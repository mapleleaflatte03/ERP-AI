# =============================================================================
# ERPX LLM Configuration
# =============================================================================
# Copy this file to /root/erp-ai/configs/llm.env and fill in values

# -----------------------------------------------------------------------------
# LLM PROVIDER SELECTION
# -----------------------------------------------------------------------------
# Options: "do_agent" | "local"
# - do_agent: Use DigitalOcean Agent API (Qwen3-32B, recommended for production)
# - local: Use local Qwen model (CPU, slower but no API cost)
LLM_PROVIDER=do_agent

# -----------------------------------------------------------------------------
# DIGITALOCEAN AGENT API (when LLM_PROVIDER=do_agent)
# -----------------------------------------------------------------------------
# API Endpoint URL (from DO Agent dashboard)
DO_AGENT_URL=https://gdfyu2bkvuq4idxkb6x2xkpe.agents.do-ai.run

# API Key (NEVER commit this to git!)
# Get from DO Agent dashboard > API Keys
DO_AGENT_KEY=your-api-key-here

# Model to use (default: qwen3-32b)
DO_AGENT_MODEL=qwen3-32b

# Request timeout in seconds
DO_AGENT_TIMEOUT=60

# -----------------------------------------------------------------------------
# LOCAL LLM (when LLM_PROVIDER=local)
# -----------------------------------------------------------------------------
# HuggingFace model name
QWEN_MODEL=Qwen/Qwen2.5-0.5B-Instruct

# Generation parameters
LLM_MAX_NEW_TOKENS=512
LLM_TEMPERATURE=0.3
LLM_TIMEOUT_SECONDS=120

# Fallback behavior
USE_FALLBACK_ON_ERROR=true
