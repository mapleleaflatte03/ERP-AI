# Zyte Scrapy Cloud - ASOFT ERP-AI

> Scrapy project cho ERP-AI, deploy lÃªn Zyte Scrapy Cloud.

## ğŸ“ Cáº¥u trÃºc thÆ° má»¥c

```
/root/erp-ai/zyte/
â”œâ”€â”€ scrapy.cfg              # Scrapy project config
â”œâ”€â”€ scrapinghub.yml         # Zyte deployment config (Project ID: 845063)
â”œâ”€â”€ requirements.txt        # Dependencies cho Zyte
â”œâ”€â”€ output.json             # Output tá»« local test
â”œâ”€â”€ asoft_zyte/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ items.py            # Item definitions (QuoteItem, InvoiceItem)
â”‚   â”œâ”€â”€ settings.py         # Scrapy settings (safe defaults)
â”‚   â””â”€â”€ spiders/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ smoke_quotes.py # Smoke test spider
â””â”€â”€ .venv/                  # Local virtual environment
```

## ğŸ§ª Test Local

### 1. Khá»Ÿi táº¡o environment

```bash
cd /root/erp-ai/zyte
python3 -m venv .venv
source .venv/bin/activate
pip install -U pip
pip install -r requirements.txt
```

### 2. Liá»‡t kÃª spiders

```bash
scrapy list
# Output: smoke_quotes
```

### 3. Cháº¡y spider local

```bash
# Output ra file JSON
scrapy crawl smoke_quotes -O output.json

# Hoáº·c cháº¡y vÃ  xem log realtime
scrapy crawl smoke_quotes -L DEBUG
```

### 4. Kiá»ƒm tra output

```bash
head -50 output.json
# Hoáº·c
cat output.json | python3 -m json.tool | head -100
```

## ğŸš€ Deploy lÃªn Zyte Scrapy Cloud

### 1. CÃ i shub

```bash
cd /root/erp-ai/zyte
source .venv/bin/activate
pip install -U shub
```

### 2. Login Zyte (INTERACTIVE - khÃ´ng lÆ°u key vÃ o file)

```bash
shub login
# Nháº­p API key khi Ä‘Æ°á»£c há»i
# API key: <láº¥y tá»« Zyte Dashboard -> API keys>
```

> âš ï¸ **QUAN TRá»ŒNG**: KHÃ”NG commit API key vÃ o repo. Key chá»‰ nháº­p qua `shub login`.

### 3. Deploy

```bash
shub deploy 845063
# 845063 = Zyte Project ID
```

Output thÃ nh cÃ´ng:
```
Deploying to project 845063
Deploy successful!
```

## ğŸ¯ Cháº¡y Job trÃªn Zyte Dashboard

1. **ÄÄƒng nháº­p**: https://app.zyte.com/
2. **VÃ o project**: Click vÃ o project `845063` hoáº·c tÃªn báº¡n Ä‘áº·t
3. **Spiders tab**: Click "Spiders" á»Ÿ sidebar
4. **Cháº¡y spider**: 
   - Chá»n `smoke_quotes`
   - Click **"Run"** button
5. **Xem job**:
   - Job list hiá»‡n á»Ÿ **"Jobs"** tab
   - Click vÃ o job ID Ä‘á»ƒ xem chi tiáº¿t

## ğŸ“Š Xem Logs & Output

### TrÃªn Zyte Dashboard:

1. **Jobs â†’ [job_id] â†’ Logs**: Xem log realtime
2. **Jobs â†’ [job_id] â†’ Items**: Xem items Ä‘Ã£ scrape
3. **Jobs â†’ [job_id] â†’ Stats**: Xem thá»‘ng kÃª (requests, items, errors)

### Qua CLI:

```bash
# Xem logs cá»§a job
shub log 845063/1/1

# Táº£i items vá»
shub items 845063/1/1 -o items.jl
```

## âš™ï¸ Äá»•i URL Target

### CÃ¡ch 1: Sá»­a spider code

Edit file `asoft_zyte/spiders/smoke_quotes.py`:

```python
class SmokeQuotesSpider(scrapy.Spider):
    name = "smoke_quotes"
    allowed_domains = ["your-new-domain.com"]
    start_urls = ["https://your-new-domain.com/page"]
```

Sau Ä‘Ã³ re-deploy:
```bash
shub deploy 845063
```

### CÃ¡ch 2: Truyá»n URL qua arguments (khÃ´ng cáº§n re-deploy)

Sá»­a spider Ä‘á»ƒ nháº­n argument:

```python
def __init__(self, start_url=None, *args, **kwargs):
    super().__init__(*args, **kwargs)
    if start_url:
        self.start_urls = [start_url]
```

Cháº¡y vá»›i custom URL:
```bash
# Local
scrapy crawl smoke_quotes -a start_url="https://example.com"

# TrÃªn Zyte Dashboard: thÃªm argument trong Run dialog
```

## ğŸ” Security Notes

| Item | Tráº¡ng thÃ¡i |
|------|-----------|
| API key trong repo | âŒ KHÃ”NG (interactive login) |
| Secrets trong code | âŒ KHÃ”NG |
| `.venv/` trong git | âŒ KHÃ”NG (Ä‘Ã£ cÃ³ trong .gitignore) |
| `output/` trong git | âŒ KHÃ”NG |

## ğŸ“ Settings Quan Trá»ng (settings.py)

```python
ROBOTSTXT_OBEY = True       # TuÃ¢n thá»§ robots.txt
DOWNLOAD_DELAY = 1          # 1 giÃ¢y giá»¯a requests
CONCURRENT_REQUESTS = 2     # Max 2 requests cÃ¹ng lÃºc
AUTOTHROTTLE_ENABLED = True # Tá»± Ä‘iá»u chá»‰nh tá»‘c Ä‘á»™
CLOSESPIDER_ITEMCOUNT = 20  # Giá»›i háº¡n 20 items (safety)
```

## ğŸ†˜ Troubleshooting

### Lá»—i "shub: command not found"
```bash
source .venv/bin/activate
pip install -U shub
```

### Lá»—i "No project found"
```bash
# Äáº£m báº£o Ä‘ang á»Ÿ Ä‘Ãºng thÆ° má»¥c
cd /root/erp-ai/zyte
ls scrapy.cfg  # Pháº£i tháº¥y file nÃ y
```

### Lá»—i "Authentication failed"
```bash
shub logout
shub login  # Nháº­p láº¡i API key
```

### Spider khÃ´ng cháº¡y trÃªn Zyte
- Kiá»ƒm tra requirements.txt cÃ³ Ä‘á»§ dependencies
- Xem logs trÃªn Dashboard Ä‘á»ƒ biáº¿t lá»—i cá»¥ thá»ƒ

## ğŸ“š TÃ i liá»‡u tham kháº£o

- [Scrapy Documentation](https://docs.scrapy.org/)
- [Zyte Scrapy Cloud Docs](https://docs.zyte.com/scrapy-cloud/)
- [shub CLI Reference](https://shub.readthedocs.io/)

---

## ğŸ” Spider: asoft_probe (API Discovery)

### Má»¥c Ä‘Ã­ch
Scan nháº¹ trang public index.html Ä‘á»ƒ tÃ¬m:
- Internal links (`<a href>`)
- Script assets (`<script src>`)
- API endpoint hints (`/api/`, `/swagger`, `/v1/`, etc.)

### Safety Settings (KHÃ”NG thay Ä‘á»•i)
```python
ROBOTSTXT_OBEY = True
DOWNLOAD_DELAY = 2
CONCURRENT_REQUESTS = 1
CLOSESPIDER_PAGECOUNT = 15
DOWNLOAD_TIMEOUT = 10
```

### Cháº¡y Local
```bash
cd /root/erp-ai/zyte
source .venv/bin/activate

# Default target
scrapy crawl asoft_probe -O output_probe.json

# Custom target
scrapy crawl asoft_probe -a base_url="http://example.com/index.html" -O output.json
```

### Cháº¡y trÃªn Zyte Dashboard
1. **ÄÄƒng nháº­p**: https://app.zyte.com/
2. **Project**: 845063
3. **Spiders** â†’ `asoft_probe` â†’ **Run**
4. (Optional) ThÃªm argument: `base_url=http://your-target.com/index.html`
5. **Jobs** â†’ Click job ID â†’ **Items** Ä‘á»ƒ xem káº¿t quáº£

### Output Fields
| Field | Description |
|-------|-------------|
| `kind` | `page`, `link`, `script`, `api_hint` |
| `value` | URL hoáº·c API pattern tÃ¬m Ä‘Æ°á»£c |
| `source_url` | URL nÆ¡i phÃ¡t hiá»‡n |
| `base_url` | Target gá»‘c |

### âš ï¸ LÆ°u Ã½
- Chá»‰ cháº¡y **1 láº§n** khi cáº§n discovery
- KHÃ”NG spam target
- Xem `api_hint` items Ä‘á»ƒ tÃ¬m endpoints

---

**Snapshot backup trÆ°á»›c khi thÃªm Zyte**: `/root/erp-ai_snapshot_before_zyte.tar.gz`

**Zyte Project ID**: `845063`

**Spiders**: `smoke_quotes`, `asoft_probe`

**Last updated**: 2026-01-17
